{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:43.090505347Z",
     "start_time": "2026-02-26T20:25:43.073474772Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib.table import table\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as grid_spec\n",
    "import jinja2\n",
    "import re\n",
    "import tabulate\n",
    "import ridgeplot as rg\n",
    "import nbformat\n",
    "from sympy import true\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "from IPython.display import IFrame\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "#a"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:44.760084196Z",
     "start_time": "2026-02-26T20:25:43.091661348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Justin Li\n",
    "# Basically, we're just trying to clean the dataset up so that the street names are more consistent.\n",
    "df = pd.read_csv(\"2012-24_Crash_Events.csv\")\n",
    "print(df.columns)\n",
    "column_nan_count = df['OnStreet'].isnull()\n",
    "print(column_nan_count.sum())\n",
    "column_unknown_count = df[(df['OnStreet'] == 'Unknown')]\n",
    "print(column_nan_count.count())\n",
    "\n",
    "df[\"OnStreet\"] = df[\"OnStreet\"].fillna(\"Unknown\").astype(str)\n",
    "column_nan_count = df['OnStreet'].isnull()\n",
    "\n",
    "print(column_nan_count.sum())\n",
    "column_unknown_count = df[(df['OnStreet'] == 'Unknown')]\n",
    "print(column_nan_count.count())\n",
    "df_streetsort = df.sort_values(by=['OnStreet'], inplace=True,)\n",
    "\n",
    "\n"
   ],
   "id": "e15c404b03b714a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17434/2334159630.py:3: DtypeWarning:\n",
      "\n",
      "Columns (0: CaseNumber) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CaseNumber', 'CaseYear', 'CrashDate', 'CrashTime',\n",
      "       'CrashTimeFormatted', 'CrashTypeCde', 'CrashType', 'CollisionType',\n",
      "       'CrashSeverity', 'LightCondition', 'WeatherCondition',\n",
      "       'RoadwayAccessControlCde', 'RoadwayCharacteristic',\n",
      "       'RoadSurfaceCondition', 'TrafficControl', 'TrafficWay',\n",
      "       'MaxInjurySeverity', 'NumberOfFatalities', 'NumberOfInjuries',\n",
      "       'NumberOfSeriousInjuries', 'NumberOfOtherInjuries', 'NumberOfVehicles',\n",
      "       'PoliceDept', 'ReportingAgency', 'Precinct',\n",
      "       'CommercialVehicleCrashInd', 'PPDRCode', 'NonReportable',\n",
      "       'ReviewedIndicator', 'DMVInsertDate', 'CountyFIPS', 'CountyName',\n",
      "       'MuniFIPS', 'CityTownName', 'OnStreet', 'ClosestCrossStreet',\n",
      "       'MasterIntersectionId', 'IntersectionIndicator', 'ReferenceMarker',\n",
      "       'DistanceFromIntersection', 'DirectionFromIntersection', 'UTMEasting',\n",
      "       'UTMNorthing', 'NonPublicWayCode', 'ACCESS_CONTROL', 'DIVIDED',\n",
      "       'FUNCTIONAL_CLASS', 'MAINT_JURISDICTION_TYPE_ID',\n",
      "       'OWNING_JURISDICTION_TYPE_ID', 'NAME', 'POSTED_SPEED', 'VehicleTypes',\n",
      "       'VehicleBodyTypes', 'CommercialVehicles', 'PreCrashActions',\n",
      "       'isLargeTruckCrash', 'DriverAgeVehicleOne', 'DriverAgeVehicleTwo',\n",
      "       'DriverAgeVehicleThree', 'DriverAgeVehicleFour', 'DriverAgeVehicleFive',\n",
      "       'PersonTypes', 'PersonInjuries', 'ApparentFactors',\n",
      "       'ApparentFactorCodes'],\n",
      "      dtype='str')\n",
      "3575\n",
      "291634\n",
      "0\n",
      "291634\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:44.790928510Z",
     "start_time": "2026-02-26T20:25:44.773707683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onstreetnames = pd.unique(df['OnStreet'])\n",
    "onstreetnames = onstreetnames.tolist()\n",
    "\n",
    "\n",
    "with open(\"Street_names.txt\", \"w\") as output:\n",
    "    output.write(str(onstreetnames))\n"
   ],
   "id": "61a63f2206e0cb88",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2143ff7e1edebed1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:44.802280986Z",
     "start_time": "2026-02-26T20:25:44.791615844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "abbrev = {\n",
    "    'ST': 'STREET',\n",
    "    'RD': 'ROAD',\n",
    "    'AVE': 'AVENUE',\n",
    "    'AV': 'AVENUE',\n",
    "    'BLVD': 'BOULEVARD',\n",
    "    'LN': 'LANE',\n",
    "    'DR': 'DRIVE',\n",
    "    'CIR': 'CIRCLE',\n",
    "    'CT': 'COURT',\n",
    "    'PKWY': 'PARKWAY',\n",
    "    'PKY': 'PARKWAY',\n",
    "    'PL': 'PLACE',\n",
    "    'TER': 'TERRACE',\n",
    "    'TRL': 'TRAIL',\n",
    "    'WAY': 'WAY',\n",
    "    'HWY': 'HIGHWAY',\n",
    "    'ALY': 'ALLEY',\n",
    "    'AL': 'ALLEY',\n",
    "    'CRES': 'CRESCENT',\n",
    "    'KNL': 'KNOLL',\n",
    "    'KN': 'KNOLL',\n",
    "    'PIKE': 'PIKE',\n",
    "    'MNR': 'MANOR',\n",
    "    'GRV': 'GROVE',\n",
    "    'HL': 'HILL',\n",
    "    'TL': 'TOWN LINE',\n",
    "    'EXT': 'EXTENSION',\n",
    "    'RTE': 'STATE ROUTE',\n",
    "    'RT': 'STATE ROUTE',\n",
    "    'XING': 'CROSSING',\n",
    "    'XNG': 'CROSSING',\n",
    "    'RDG': 'RIDGE',\n",
    "}\n",
    "\n",
    "directions = {\n",
    "    'N': 'NORTH',\n",
    "    'S': 'SOUTH',\n",
    "    'E': 'EAST',\n",
    "    'W': 'WEST',\n",
    "}\n",
    "\n",
    "ordinals = {\n",
    "    '1ST': 'FIRST',\n",
    "    '2ND': 'SECOND',\n",
    "    '3RD': 'THIRD',\n",
    "    '4TH': 'FOURTH',\n",
    "    '5TH': 'FIFTH',\n",
    "    '6TH': 'SIXTH',\n",
    "    '7TH': 'SEVENTH',\n",
    "    '8TH': 'EIGHTH',\n",
    "    '9TH': 'NINTH',\n",
    "    '10TH': 'TENTH',\n",
    "}\n",
    "\n",
    "directional_terms = r'\\b( NORTH| SOUTH| EAST| WEST|NORTHBOUND|SOUTHBOUND|EASTBOUND|WESTBOUND|NB|SB|EB|WB)\\b'"
   ],
   "id": "1801df51a3f67eb9",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:44.811834497Z",
     "start_time": "2026-02-26T20:25:44.802854844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grok generated this cell's code and the stuff immediately above. Generally speaking it takes the name, makes it uppercase, and does a bunch of regex to sub in the abbrevs. shown above.\n",
    "# There are some concerns from the resulting code -- eg, Abbot street vs. Abbott street. I'll ultimately need Xinyi to take a look, make sure those aren't the same streets.\n",
    "# Also a lot of streets are just numbers. I'm not sure what those might be, but I'm thinking it's a code for State Routes or Interstates? But iunno.\n",
    "def standardize_street(name):\n",
    "\n",
    "    firstname = name\n",
    "    name = name.upper().strip()\n",
    "\n",
    "    # Split concatenated suffixes (e.g., 'greyst' -> 'GREY ST')\n",
    "    #suffixes = '|'.join(map(re.escape, list(abbrev.keys()) + list(abbrev.values())))\n",
    "    #name = re.sub(r'([A-Z\\d]+)(' + suffixes + r')$', r'\\1 \\2', name)\n",
    "\n",
    "    # Replace ordinals\n",
    "    for k, v in ordinals.items():\n",
    "        name = re.sub(r'\\b' + re.escape(k) + r'\\b', v, name)\n",
    "\n",
    "    # Handle interstates (I 490, I-490 → INTERSTATE 490)\n",
    "    name = re.sub(r'\\bI\\s*-?\\s*(\\d+)\\b', r'INTERSTATE \\1', name)\n",
    "\n",
    "    # Handle NY routes (NY104 → STATE ROUTE 104)\n",
    "    name = re.sub(r'\\bNY(\\d+[A-Z]?)\\b', r'STATE ROUTE \\1', name)\n",
    "\n",
    "    # Handle routes and common typos (expand RT, etc.)\n",
    "    name = re.sub(r'\\[ROUTE\\]\\s*(\\d+)', r'STATE ROUTE \\1', name)\n",
    "    name = re.sub(r'\\bRT\\s*(\\d+[A-Z]?)\\b', r'STATE ROUTE \\1', name)\n",
    "    name = re.sub(r'STATE HWY\\s*(\\d+[A-Z]?)', r'STATE ROUTE \\1', name)\n",
    "    name = re.sub(r'STATE RTE\\s*(\\d+[A-Z]?)', r'STATE ROUTE \\1', name)\n",
    "    name = re.sub(r'STHY\\s*(\\d+[A-Z]?)', r'STATE ROUTE \\1', name)\n",
    "\n",
    "    # Remove exits (e.g., \"EXIT 23 STATE ROUTE 390\" → \"STATE ROUTE 390\")\n",
    "    name = re.sub(r'EXIT\\s*\\d+\\s*', '', name)\n",
    "\n",
    "    # Remove ramps (e.g., \"RAMP TO INTERSTATE 490\" → \"INTERSTATE 490\")\n",
    "    name = re.sub(r'RAMP\\s*(TO|FROM)?\\s*', '', name)\n",
    "\n",
    "    # Remove directional terms\n",
    "    name = re.sub(directional_terms, '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()  # Clean extra spaces\n",
    "\n",
    "    # Standardize words (directions expanded earlier, but now removed if present)\n",
    "    words = name.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in abbrev:\n",
    "            new_words.append(abbrev[word])\n",
    "        elif word in directions:\n",
    "            new_words.append(directions[word])\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    newname = ' '.join(new_words)\n",
    "    if newname == 'AVENUE':\n",
    "        print(firstname)\n",
    "    return newname"
   ],
   "id": "2c03abf3eb15d243",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:44.821554355Z",
     "start_time": "2026-02-26T20:25:44.812498364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Because the above code doesn't catch stuff like \"390\" being State Route 390, I had to handcode this.\n",
    "#'104', '15A', '251', '31F', '33', '383', '390', '441', '490', '590'\n",
    "\n",
    "def numberlookup(num):\n",
    "    match num:\n",
    "        case \"104\":\n",
    "            return \"STATE ROUTE 104\"\n",
    "        case \"15A\":\n",
    "            return \"STATE ROUTE 15A\"\n",
    "        case \"251\":\n",
    "            return \"STATE ROUTE 251\"\n",
    "        case \"31F\":\n",
    "            return \"STATE ROUTE 31F\"\n",
    "        case \"33\":\n",
    "            return \"STATE ROUTE 33\"\n",
    "        case \"65\":\n",
    "            return \"STATE ROUTE 65\"\n",
    "        case \"383\":\n",
    "            return \"STATE ROUTE 33\"\n",
    "        #case \"390\":\n",
    "        #   return  \"STATE ROUTE 390\"\n",
    "        case \"441\":\n",
    "            return \"STATE ROUTE 441\"\n",
    "        case \"490\":\n",
    "            return \"INTERSTATE 490\"\n",
    "        case \"590\":\n",
    "            return \"INTERSTATE 590\"\n",
    "        case _:\n",
    "            return num\n",
    "\n"
   ],
   "id": "f31fcea8e33509cd",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:55.965686705Z",
     "start_time": "2026-02-26T20:25:44.822314548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['OnStreet_standardized'] = df['OnStreet'].apply(standardize_street)\n",
    "df['OnStreet_standardized'] = df['OnStreet_standardized'].apply(numberlookup)\n",
    "df.to_csv('2012-24_Crash_Events_std_street_names_dataset.csv', index=False)\n",
    "\n",
    "# Check reduction in uniques\n",
    "print(f\"Original uniques: {len(df['OnStreet'].unique())}\")\n",
    "print(f\"Standardized uniques: {len(df['OnStreet_standardized'].unique())}\")"
   ],
   "id": "9111241ac66b26bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original uniques: 9509\n",
      "Standardized uniques: 6331\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:56.285927206Z",
     "start_time": "2026-02-26T20:25:55.981077204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_streetsort = df.sort_values(by=['OnStreet_standardized'])\n",
    "\n",
    "onstreetnames = pd.unique(df_streetsort['OnStreet_standardized'])\n",
    "onstreetnames = onstreetnames.tolist()\n",
    "onstreetnames\n",
    "with open(\"Street_std_names.txt\", \"w\") as output:\n",
    "    output.write(str(onstreetnames))\n"
   ],
   "id": "efc8ad5d7a42466d",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:56.312001020Z",
     "start_time": "2026-02-26T20:25:56.287381784Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "ef5efcd51ba5d2a7",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:56.335389646Z",
     "start_time": "2026-02-26T20:25:56.312992179Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2baeb621d09ae555",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:25:56.358953508Z",
     "start_time": "2026-02-26T20:25:56.337725475Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f8af32610040219e",
   "outputs": [],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
